Time (in seconds) report for run: test-turbine using mode:turbine todtype:default backend:llvm-cpu

| tests                                            |   model-run |   onnx-import |   torch-mlir |   iree-compile |   inference |
|:-------------------------------------------------|------------:|--------------:|-------------:|---------------:|------------:|
| pytorch/models/t5-large                          |      34.743 |             0 |            0 |         26.413 |       5.421 |
| pytorch/models/bert-large-uncased                |      22.008 |             0 |            0 |         11.554 |       0.607 |
| pytorch/models/mit-b0                            |       7.374 |             0 |            0 |          4.049 |       0.214 |
| pytorch/models/llama2-7b-GPTQ                    |     781.155 |             0 |            0 |          0     |       0     |
| pytorch/models/opt-350m                          |      20.159 |             0 |            0 |         12.456 |       0.572 |
| pytorch/models/mobilebert-uncased                |      14.866 |             0 |            0 |         10.337 |       0.108 |
| pytorch/models/dlrm                              |       6.338 |             0 |            0 |          0     |       0     |
| pytorch/models/opt-1.3b                          |      60.58  |             0 |            0 |         35.413 |       2.008 |
| pytorch/models/whisper-base                      |       5.762 |             0 |            0 |          3.117 |       0.165 |
| pytorch/models/phi-2                             |     123.653 |             0 |            0 |         63.282 |       8.511 |
| pytorch/models/bge-base-en-v1.5                  |      10.784 |             0 |            0 |          5.612 |       0.251 |
| pytorch/models/miniLM-L12-H384-uncased           |       8.88  |             0 |            0 |          3.698 |       0.116 |
| pytorch/models/llama2-7b-hf                      |     290.282 |             0 |            0 |        245.46  |       9.17  |
| pytorch/models/phi-1_5                           |      62.951 |             0 |            0 |         34.494 |       6.649 |
| pytorch/models/t5-base                           |      15.393 |             0 |            0 |         10.416 |       1.807 |
| pytorch/models/bart-large                        |      16.995 |             0 |            0 |          8.634 |       0.469 |
| pytorch/models/vit-base-patch16-224              |       6.662 |             0 |            0 |          4.107 |       0.396 |
| pytorch/models/resnet50                          |       4.957 |             0 |            0 |          3.965 |       0.181 |
| pytorch/models/beit-base-patch16-224-pt22k-ft22k |       8.381 |             0 |            0 |          4.634 |       0.412 |
| pytorch/models/whisper-medium                    |      20.159 |             0 |            0 |         13.5   |       0.724 |
| pytorch/models/opt-125M                          |      12.02  |             0 |            0 |          6.11  |       0.315 |
| pytorch/models/gpt2                              |      12.11  |             0 |            0 |          3.742 |       0     |
| pytorch/models/stablelm-3b-4e1t                  |       1.066 |             0 |            0 |          0     |       0     |
| pytorch/models/gemma-7b                          |       0.929 |             0 |            0 |          0     |       0     |
| pytorch/models/gpt2-xl                           |      78.528 |             0 |            0 |         29.336 |       0     |
| pytorch/models/opt-125m-gptq                     |      17.123 |             0 |            0 |          7.384 |       0.242 |
| pytorch/models/deit-small-distilled-patch16-224  |       5.328 |             0 |            0 |          2.931 |       0.157 |
| pytorch/models/whisper-small                     |      11.992 |             0 |            0 |          6.071 |       0.326 |
